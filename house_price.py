# -*- coding: utf-8 -*-
"""House_price.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rzQ9A7_AsJOyA8sx2caeW1bGOGmKNRca

Ev Fiyat Tahmin Modeli

İş Problemi

Her bir eve ait özelliklerin ve ev fiyatlarının bulunduğu veriseti kullanılarak, farklı tipteki evlerin fiyatlarına ilişkin bir makine öğrenmesi projesi gerçekleştirilmek istenmektedir.

Veri Seti Hikayesi

 Ames, Lowa’daki konut evlerinden oluşan bu veri seti içerisinde 79 açıklayıcı değişken bulunduruyor. Kaggle üzerinde bir yarışması da bulunan projenin veri seti ve yarışma sayfasına aşağıdaki linkten ulaşabilirsiniz. Veri seti bir kaggle yarışmasına ait olduğundan dolayı train ve test olmak üzere iki farklı csv dosyası vardır. Test veri setinde ev fiyatları boş bırakılmış olup, bu değerleri sizin tahmin etmeniz beklenmektedir.

Görev

Elimizdeki veri seti üzerinden minimum hata ile ev fiyatlarını tahmin eden bir makine öğrenmesi modeli geliştiriniz.
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import GridSearchCV, cross_validate
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
!pip install catboost
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,roc_auc_score
from catboost import CatBoostClassifier
from lightgbm import LGBMClassifier
from xgboost import XGBClassifier
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler, RobustScaler
from sklearn.linear_model import LinearRegression, Ridge, Lasso, LassoCV
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from xgboost import XGBRegressor
from lightgbm import LGBMRegressor
from catboost import CatBoostRegressor

from sklearn.neighbors import KNeighborsRegressor
from sklearn.svm import SVR
from sklearn.tree import DecisionTreeRegressor


pd.set_option('display.max_columns', None)
pd.set_option('display.width', 170)
pd.set_option('display.max_rows', None)
pd.set_option('display.float_format', lambda x: '%.3f' % x)
import warnings
warnings.filterwarnings("ignore", category=DeprecationWarning)
warnings.filterwarnings("ignore", category=FutureWarning)
from google.colab import drive
train = pd.read_csv("/content/sample_data/train.csv")
test = pd.read_csv("/content/sample_data/test.csv")

from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet

df = train.append(test).reset_index(drop=True)

df.head()

df.shape

# Görev 1 : Keşifçi Veri Analizi(EDA)

def check_df(dataframe, head=5):
    print("##################### Shape #####################")
    print(dataframe.shape)
    print("##################### Types #####################")
    print(dataframe.dtypes)
    print("##################### Head #####################")
    print(dataframe.head(head))
    print("##################### Tail #####################")
    print(dataframe.tail(head))
    print("##################### NA #####################")
    print(dataframe.isnull().sum())
    print("##################### Quantiles #####################")
    print(dataframe.quantile([0, 0.05, 0.50, 0.95, 0.99, 1]).T)

check_df(df)

# Numerik ve kategorik değişkenlerin veri içindeki dağılımı
def grab_col_names(dataframe, cat_th=10, car_th=20):
    """

    Veri setindeki kategorik, numerik ve kategorik fakat kardinal değişkenlerin isimlerini verir.
    Not: Kategorik değişkenlerin içerisine numerik görünümlü kategorik değişkenler de dahildir.

    Parameters
    ------
        dataframe: dataframe
                Değişken isimleri alınmak istenilen dataframe
        cat_th: int, optional
                numerik fakat kategorik olan değişkenler için sınıf eşik değeri
        car_th: int, optional
                kategorik fakat kardinal değişkenler için sınıf eşik değeri

    Returns
    ------
        cat_cols: list
                Kategorik değişken listesi
        num_cols: list
                Numerik değişken listesi
        cat_but_car: list
                Kategorik görünümlü kardinal değişken listesi

    Examples
    ------
        import seaborn as sns
        df = sns.load_dataset("iris")
        print(grab_col_names(df))


    Notes
    ------
        cat_cols + num_cols + cat_but_car = toplam değişken sayısı
        num_but_cat cat_cols'un içerisinde.

    """
    # cat_cols, cat_but_car
    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == "O"]
    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and dataframe[col].dtypes != "O"]
    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and dataframe[col].dtypes == "O"]
    cat_cols = cat_cols + num_but_cat
    cat_cols = [col for col in cat_cols if col not in cat_but_car]

    # num_cols
    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != "O"]
    num_cols = [col for col in num_cols if col not in num_but_cat]

    print(f"Observations: {dataframe.shape[0]}")
    print(f"Variables: {dataframe.shape[1]}")
    print(f'cat_cols: {len(cat_cols)}')
    print(f'num_cols: {len(num_cols)}')
    print(f'cat_but_car: {len(cat_but_car)}')
    print(f'num_but_cat: {len(num_but_cat)}')

    return cat_cols, num_cols, cat_but_car

cat_cols, num_cols, cat_but_car = grab_col_names(df)

# KATEGORİK DEĞİŞKENLERİN ANALİZİ
def cat_summary(dataframe, col_name, plot=False):
    print(pd.DataFrame({col_name: dataframe[col_name].value_counts(),
                        "Ratio": 100 * dataframe[col_name].value_counts() / len(dataframe)}))
    print("##########################################")
    if plot:
        sns.countplot(x=dataframe[col_name], data=dataframe)
        plt.show()

for col in cat_cols:
    cat_summary(df, col, plot=True)

# NUMERİK DEĞİŞKENLERİN ANALİZİ
def num_summary(dataframe, numerical_col, plot=False):
    quantiles = [0.05, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90, 0.95, 0.99]
    print(dataframe[numerical_col].describe(quantiles).T)

    if plot:
        dataframe[numerical_col].hist(bins=20)
        plt.xlabel(numerical_col)
        plt.title(numerical_col)
        plt.show()

for col in num_cols:
    num_summary(df, col, plot=True)

df.head()

# Kategorik değişkenler ile hedef değişken incelemesi

def target_summary_with_num(dataframe, target, numerical_col):
    print(dataframe.groupby(target).agg({numerical_col: "mean"}), end="\n\n\n")

for col in num_cols:
    target_summary_with_num(df, "SalePrice", col)

# KATEGORİK DEĞİŞKENLERİN TARGET GÖRE ANALİZİ
##################################

def target_summary_with_cat(dataframe, target, categorical_col):
    print(categorical_col)
    print(pd.DataFrame({"TARGET_MEAN": dataframe.groupby(categorical_col)[target].mean(),
                        "Count": dataframe[categorical_col].value_counts(),
                        "Ratio": 100 * dataframe[categorical_col].value_counts() / len(dataframe)}), end="\n\n\n")

for col in cat_cols:
    target_summary_with_cat(df, "SalePrice", col)

# Kategorik değişkenleri "SalePrice" özelinde görselleştirip inceleyelim
for col in cat_cols:
    graph = pd.crosstab(index=df['SalePrice'], columns=df[col]).plot.bar(figsize=(7, 4), rot=0)
    plt.show()

# Aykırı gözlem var mı 

def outlier_thresholds(dataframe, col_name, q1=0.10, q3=0.90):
    quartile1 = dataframe[col_name].quantile(q1)
    quartile3 = dataframe[col_name].quantile(q3)
    interquantile_range = quartile3 - quartile1
    up_limit = quartile3 + 1.5 * interquantile_range
    low_limit = quartile1 - 1.5 * interquantile_range
    return low_limit, up_limit


def check_outlier(dataframe, col_name):
    low_limit, up_limit = outlier_thresholds(dataframe, col_name)
    if dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)].any(axis=None):
        return True
    else:
        return False

for col in num_cols:
    print(col, ": ", check_outlier(df, col))

def replace_with_thresholds(dataframe, variable):
    low_limit, up_limit = outlier_thresholds(dataframe, variable)
    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit
    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit

for col in num_cols:
    # print(col)
    replace_with_thresholds(df, col)

for col in num_cols:
    print(col, ": ", check_outlier(df, col))

# Eksik gözlem var mı

def missing_values_table(dataframe, na_name=False):
    na_columns = [col for col in dataframe.columns if dataframe[col].isnull().sum() > 0]

    n_miss = dataframe[na_columns].isnull().sum().sort_values(ascending=False)
    ratio = (dataframe[na_columns].isnull().sum() / dataframe.shape[0] * 100).sort_values(ascending=False)
    missing_df = pd.concat([n_miss, np.round(ratio, 2)], axis=1, keys=['n_miss', 'ratio'])
    print(missing_df, end="\n")

    if na_name:
        return na_columns

missing_values_table(df)

df['MiscFeature'].value_counts()

df.info()

df['MiscFeature'].unique()

df['MiscFeature'].nunique()

df.info()

no_cols = ["Alley","BsmtQual","BsmtCond","BsmtExposure","BsmtFinType1","BsmtFinType2","FireplaceQu",
           "GarageType","GarageFinish","GarageQual","GarageCond","PoolQC","Fence","MiscFeature"]

# Kolonlardaki boşlukların "No" ifadesi ile doldurulması
for col in no_cols:
    df[col].fillna("No",inplace=True)

missing_values_table(df)

[col for col in df.columns if (df[col].isnull().sum() > 0) & (df[col].dtype != "O") & (col not in 'SalePrice')]

def fill_missing_na(df, cat_length, target='SalePrice', num=True, obj=True):
  object_cols = [col for col in df.columns if (df[col].isnull().sum() > 0) & (df[col].dtype == "O")]
  num_cols = [col for col in df.columns if (df[col].isnull().sum() > 0) & (df[col].dtype != "O")]# & (col not in target)]
  temp_target = df[target]
  print('Categorical cols:\n', object_cols, '\n')
  print('Numeric cols:\n', num_cols, '\n')
  
  if num:
    df = df.apply(lambda x: x.fillna(x.mean()) if x.dtype != "O" else x, axis=0)
    num_cols = [col for col in df.columns if (df[col].isnull().sum() > 0) & (df[col].dtype != "O") & (col not in target)]
  if obj:
    df = df.apply(lambda x: x.fillna(x.mode()[0]) if x.dtype == "O" and len(x.unique()) <= cat_length else x, axis=0)
    object_cols = [col for col in df.columns if (df[col].isnull().sum() > 0) & (df[col].dtype == "O")]

  temp_target = df[target]

  print('is Nan: ', df.isnull().sum().any())
  print('Categorical cols:\n', object_cols, '\n')
  print('Numeric cols:\n', num_cols, '\n')

  return df

df = fill_missing_na(df, 20)

df.head()

missing_values_table(df)

df[col].isnull().sum() > 0

# Rare Encoding

cat_cols = grab_col_names(df)[0]

 # Her bir kategorik değişkenin sınıf frekanslarına ve target değişken ortalamasına bakalım:
def rare_analyser(dataframe, target, cat_cols):
    for col in cat_cols:
        print(col, ":", len(dataframe[col].value_counts()))
        print(pd.DataFrame({"COUNT": dataframe[col].value_counts(),
                            "RATIO": dataframe[col].value_counts() / len(dataframe),
                            "TARGET_MEAN": dataframe.groupby(col)[target].mean()}), end="\n\n\n")

rare_analyser(df, "SalePrice", cat_cols)

# Sınıf sayısının tek olması ya da 2 sınıflı değişkenden sınıflardan birinin frekanslarının %1 in altında olması
# bu değişkenin açıklayıcılığının olmadığını gösterir, bu değişkenleri silebiliriz:

useless_cols = [col for col in df.columns if ((df[col].nunique() == 2
                                            and (df[col].value_counts() / len(df) < 0.01).any(axis=None))
                                            | df[col].nunique() == 1)]
print(useless_cols)

df.drop(useless_cols, axis=1, inplace=True)

# Rare Encoding: Sınıf frekansı çok düşük olan (örneğin %1, 2 den fazla sınıfı bulunan değişkenlerde düşük frekanslıları
# rare kategorisi altında birleştirerek, operasyonal maliyeti düşürebiliriz)

def rare_encoder(dataframe, rare_perc, cat_cols):
    rare_columns = [col for col in cat_cols if (dataframe[col].value_counts() / len(dataframe) <= rare_perc).sum() > 1]

    for col in rare_columns:
        tmp = dataframe[col].value_counts() / len(dataframe) # th altında kalan sınıfı olan değişkenlerin sınıf frekanslarından olusan df yarat
        rare_labels = tmp[tmp <= rare_perc].index # sınıf frekansı < th olanların indexlerini bul
        dataframe[col] = np.where(dataframe[col].isin(rare_labels), 'Rare', dataframe[col]) # th altında kalan değerleri Rare olarak grupla

    return dataframe

cat_cols = grab_col_names(df)[0]
df = rare_encoder(df, 0.01, cat_cols)

rare_analyser(df, "SalePrice", cat_cols)

df.head()

missing_values_table(df)

grab_col_names(df)

# Correlation
df.corr()

# Korelasyon Matrisi
f, ax = plt.subplots(figsize=[15, 15])
sns.heatmap(df.corr(), annot=True, fmt=".2f", ax=ax, cmap="RdPu")
ax.set_title("Correlation Matrix", fontsize=10)
plt.show()

df.corrwith(df["SalePrice"]).sort_values(ascending=False)

"""SalePrice - mülkün dolar cinsinden satış fiyatı. Bu, tahmin etmeye çalışılan hedef değişkendir.

MSSubClass: İnşaat sınıfı

MSZoning: Genel imar sınıflandırması

LotFrontage: Mülkiyetin cadde ile doğrudan bağlantısının olup olmaması

LotArea: Parsel büyüklüğü

Street: Yol erişiminin tipi

Alley: Sokak girişi tipi

LotShape: Mülkün genel şekli

LandContour: Mülkün düzlüğü

Utulities: Mevcut hizmetlerin türü

LotConfig: Parsel yapılandırması

LandSlope: Mülkün eğimi

Neighborhood: Ames şehir sınırları içindeki fiziksel konumu

Condition1: Ana yol veya tren yoluna yakınlık

Condition2: Ana yola veya demiryoluna yakınlık (eğer ikinci bir yer varsa)

BldgType: Konut tipi

HouseStyle: Konut sitili

OverallQual: Genel malzeme ve bitiş kalitesi

OverallCond: Genel durum değerlendirmesi

YearBuilt: Orijinal yapım tarihi

YearRemodAdd: Yeniden düzenleme tarihi

RoofStyle: Çatı tipi

RoofMatl: Çatı malzemesi

Exterior1st: Evdeki dış kaplama

Exterior2nd: Evdeki dış kaplama (birden fazla malzeme varsa)

MasVnrType: Duvar kaplama türü

MasVnrArea: Kare ayaklı duvar kaplama alanı

ExterQual: Dış malzeme kalitesi

ExterCond: Malzemenin dışta mevcut durumu

Foundation: Vakıf tipi

BsmtQual: Bodrumun yüksekliği

BsmtCond: Bodrum katının genel durumu

BsmtExposure: Yürüyüş veya bahçe katı bodrum duvarları

BsmtFinType1: Bodrum bitmiş alanının kalitesi

BsmtFinSF1: Tip 1 bitmiş alanın metre karesi

BsmtFinType2: İkinci bitmiş alanın kalitesi (varsa)

BsmtFinSF2: Tip 2 bitmiş alanın metre karesi

BsmtUnfSF: Bodrumun bitmemiş alanın metre karesi

TotalBsmtSF: Bodrum alanının toplam metre karesi

Heating: Isıtma tipi

HeatingQC: Isıtma kalitesi ve durumu

CentralAir: Merkezi klima

Electrical: elektrik sistemi

1stFlrSF: Birinci Kat metre kare alanı

2ndFlrSF: İkinci kat metre kare alanı

LowQualFinSF: Düşük kaliteli bitmiş alanlar (tüm katlar)

GrLivArea: Üstü (zemin) oturma alanı metre karesi

BsmtFullBath: Bodrum katındaki tam banyolar

BsmtHalfBath: Bodrum katındaki yarım banyolar

FullBath: Üst katlardaki tam banyolar

HalfBath: Üst katlardaki yarım banyolar

BedroomAbvGr: Bodrum seviyesinin üstünde yatak odası sayısı

KitchenAbvGr: Bodrum seviyesinin üstünde mutfak Sayısı

KitchenQual: Mutfak kalitesi

TotRmsAbvGrd: Üst katlardaki toplam oda (banyo içermez)

Functional: Ev işlevselliği değerlendirmesi

Fireplaces: Şömineler

FireplaceQu: Şömine kalitesi

Garage Türü: Garaj yeri

GarageYrBlt: Garajın yapım yılı

GarageFinish: Garajın iç yüzeyi

GarageCars: Araç kapasitesi

GarageArea: Garajın alanı

GarageQual: Garaj kalitesi

GarageCond: Garaj durumu

PavedDrive: Garajla yol arasındaki yol

WoodDeckSF: Ayaklı ahşap güverte alanı

OpenPorchSF: Kapı önündeki açık veranda alanı

EnclosedPorch: Kapı önündeki kapalı veranda alan

3SsPorch: Üç mevsim veranda alanı

ScreenPorch: Veranda örtü alanı

PoolArea: Havuzun metre kare alanı

PoolQC: Havuz kalitesi

Fence: Çit kalitesi

MiscFeature: Diğer kategorilerde bulunmayan özellikler

MiscVal: Çeşitli özelliklerin değeri

MoSold: Satıldığı ay

YrSold: Satıldığı yıl

SaleType: Satış Türü

SaleCondition: Satış Durumu
"""

# Feature Engineering
# 1stFlrSF: Birinci Kat metre kare alanı
# GrLivArea: Üstü (zemin) oturma alanı metre karesi
df["new_1st_GrLiv"] = df["1stFlrSF"]/df["GrLivArea"]
df["new_Garage_GrLiv"] = df["GarageArea"]/df["GrLivArea"]

df["GarageQual"].value_counts()

df["GarageCond"].value_counts()

object_cols = [col for col in df.columns if df[col].dtype == "O"]

df[object_cols].value_counts()

df['BldgType'].value_counts()

# Bina son yasi
df["new_year_remodbuit"] =  df["YearRemodAdd"] - df["YearBuilt"]

# BsmtUnfSF: Bodrumun bitmemiş alanın metre karesi
# TotalBsmtSF: Bodrum alanının toplam metre karesi
df["new_BsmtSF"] =  df["TotalBsmtSF"] - df["BsmtUnfSF"]

# BsmtFullBath: Bodrum katındaki tam banyolar
# BsmtHalfBath: Bodrum katındaki yarım banyolar
df["new_BsmtAllBath"] =  df["BsmtFullBath"] + df["BsmtHalfBath"]

df2 = [col for col in df["FullBath"] if 'Rare' not in col]

df2 = pd.DataFrame (df2, columns = ['FullBathNotRare'])

# FullBath: Üst katlardaki tam banyolar
# HalfBath: Üst katlardaki yarım banyolar
df["new_AllBath_Up"] =  df2["FullBathNotRare"].astype(int) + df["HalfBath"]

# TotRmsAbvGrd: Üst katlardaki toplam oda (banyo içermez)
df["new_TotRmsAbvGrdWithBath"] =  df["TotRmsAbvGrd"] + df["new_AllBath_Up"]

# OpenPorchSF: Kapı önündeki açık veranda alanı
# EnclosedPorch: Kapı önündeki kapalı veranda alan
# 3SsPorch: Üç mevsim veranda alanı
# df["new_AllPorch"] =  df["OpenPorchSF"] + df["EnclosedPorch"] + df['3SsPorch']

[col for col in df.columns if 'porch' in col.lower()] # 3SsPorch yok

### Total Floor ###
# 1stFlrSF: Birinci Kat metre kare alanı
# 2ndFlrSF: İkinci kat metre kare alanı
# TotalBsmtSF: Bodrum alanının toplam metre karesi
# GrLivArea: Üstü (zemin) oturma alanı metre karesi
df["new_TotalFlrSF"] = df["1stFlrSF"] + df["2ndFlrSF"]
df["new_TotalHouseArea"] = df.new_TotalFlrSF + df.TotalBsmtSF
df["new_TotalSqFeet"] = df.GrLivArea + df.TotalBsmtSF

### Lot Ratio ###
# GrLivArea: Üstü (zemin) oturma alanı metre karesi
# LotArea: Parsel büyüklüğü
df["new_LotRatio"] = df.GrLivArea / df.LotArea
df["new_RatioArea"] = df.new_TotalHouseArea / df.LotArea
df["new_GarageLotRatio"] = df.GarageArea / df.LotArea

# GrLivArea: Üstü (zemin) oturma alanı metre karesi
# LotArea: Parsel büyüklüğü
# TotalBsmtSF: Bodrum alanının toplam metre karesi
# GrLivArea: Üstü (zemin) oturma alanı metre karesi
df["new_GrLivArea_LotArea"] = df["GrLivArea"] / df["LotArea"]
df["total_living_area"] = df["TotalBsmtSF"] + df["GrLivArea"]

# YrSold: Satıldığı yıl
# YearBuilt: Orijinal yapım tarihi
# YearRemodAdd: Yeniden düzenleme tarihi
df["new_HouseAge"] = df.YrSold - df.YearBuilt
df["new_RestorationAge"] = df.YrSold - df.YearRemodAdd
df["new_GarageAge"] = df.GarageYrBlt - df.YearBuilt
df["new_GarageSold"] = df.YrSold - df.GarageYrBlt

df = fill_missing_na(df, 20)

missing_values_table(df)

# Kolonlardaki boşlukların "No" ifadesi ile doldurulması
#for col in no_cols:
#    df[col].fillna("No",inplace=True)

#missing_values_table(df)

#zero_cols = ["new_AllBath_Up", "new_TotRmsAbvGrdWithBath"]
#for col in zero_cols:
#    df = df[col].fillna(df.mean(), inplace=True)
# df = df.apply(lambda x: x.fillna(x.mean()) if x.dtype != "O" else x, axis=0)
#df = fill_missing_na(df, 20)
#missing_values_table(df)

# GarageQual: Garaj kalitesi
# GarageCond: Garaj durumu
df["GarageQual"].value_counts()
df["GarageCond"].value_counts()
df["TotalGarageQual"] = df[["GarageQual", "GarageCond"]].sum(axis=1)

# LotShape: Mülkün genel şekli
df["LotShape"].value_counts()
df.loc[(df["LotShape"] == "IR2"), "LotShape"] = "IR1"
df.loc[(df["LotShape"] == "IR3"), "LotShape"] = "IR1"

df.isnull().sum()

df.shape

df.isnull().sum()

missing_values_table(df)

from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler, RobustScaler

def label_encoder(dataframe, binary_col):
    labelencoder = LabelEncoder()
    dataframe[binary_col] = labelencoder.fit_transform(dataframe[binary_col])
    return dataframe

def one_hot_encoder(dataframe, categorical_cols, drop_first=False):
    dataframe = pd.get_dummies(dataframe, columns=categorical_cols, drop_first=drop_first)
    return dataframe

##################
#  One-Hot Encoding
##################

cat_cols, num_cols, cat_but_car = grab_col_names(df)

binary_cols = [col for col in df.columns if df[col].dtypes == "O" and len(df[col].unique()) == 2]

for col in binary_cols:
    label_encoder(df, col)

df = one_hot_encoder(df, cat_cols, drop_first=True)

df.head()

df.info()

df.shape

nan_cols = [col for col in df.columns if df[col].isnull().sum() > 0]

# Kolonlardaki boşlukların "No" ifadesi ile doldurulması
for col in nan_cols:
    df[col].fillna("No",inplace=True)

missing_values_table(df)

# nan_cols = pd.DataFrame (nan_cols, columns = ['nan_cols'])

df[nan_cols].info()

df["Neighborhood"].value_counts()

df.drop("Neighborhood", axis=1, inplace=True)

from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV

# Modeling
##################################
# Adım 1: Sınıflandırma algoritmaları ile modeller kurup, accuracy skorlarını inceleyip. En iyi 4 modeli seçiniz.
##################################

y = df["SalePrice"]
X = df.drop(["SalePrice", "Id"], axis=1)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=17)

### BASE MODELS ###

models = [('LR', LinearRegression()),
          ("Ridge", Ridge()),
          ("Lasso", Lasso()),
          ("ElasticNet", ElasticNet()),
          ('KNN', KNeighborsRegressor()),
          ('CART', DecisionTreeRegressor()),
          ('RF', RandomForestRegressor()),
          ('GBM', GradientBoostingRegressor()),
          ("XGBoost", XGBRegressor(objective='reg:squarederror')),
          ("LightGBM", LGBMRegressor())]

for name, regressor in models:
    rmse = np.mean(np.sqrt(-cross_val_score(regressor, X, y, cv=5, scoring="neg_mean_squared_error")))
    print(f"RMSE: {round(rmse, 4)} ({name}) ")

# RMSE: 10209325.8848 (LR) 
# RMSE: 50066.4165 (Ridge) 
# RMSE: 48027.4584 (ElasticNet) 
# RMSE: 50641.8367 (KNN) 
# RMSE: 64902.7055 (CART) 
# RMSE: 51025.0239 (RF)
# RMSE: 51179.4866 (GBM) 
# RMSE: 50818.0795 (XGBoost) 
# RMSE: 53077.0322 (LightGBM) 


# RMSE: 135772067.8441 (LR)
# RMSE: 23513.2685 (Ridge)
# RMSE: 24449.7478 (Lasso)
# RMSE: 26869.9511 (ElasticNet)
# RMSE: 36225.8091 (KNN)
# RMSE: 35694.1323 (CART)
# RMSE: 24767.3153 (RF)
# RMSE: 22774.9258 (GBM)
# RMSE: 24659.0742 (XGBoost)
# RMSE: 22581.9479 (LightGBM)

### Hyperparameter Optimization ###

lgbm_model = LGBMRegressor(random_state=46)

rmse = np.mean(np.sqrt(-cross_val_score(lgbm_model, X, y, cv=5, scoring="neg_mean_squared_error")))

lgbm_params = {"learning_rate": [0.01, 0.1, 0.05],
               "n_estimators": [1500, 3000, 6000], # fit edilecek ağaç sayısını verir
               "colsample_bytree": [0.5, 0.7], # yeni ağaç oluşturulduğunda sütunların rastgele alt örneği
               "num_leaves": [31, 35], # ağaçta bulunacak yaprak sayısı
               "max_depth": [3, 5]} # ağacın derinliği

lgbm_gs_best = GridSearchCV(lgbm_model,
                            lgbm_params,
                            cv=3,
                            n_jobs=-1,
                            verbose=True).fit(X_train, y_train)

final_model = lgbm_model.set_params(**lgbm_gs_best.best_params_).fit(X, y)


rmse = np.mean(np.sqrt(-cross_val_score(final_model, X, y, cv=5, scoring="neg_mean_squared_error")))

lgbm_model = LGBMRegressor(learning_rate = 0.01, random_state=46)